\subsection{\bf RQ1. Comparison Results with DL-based APR Approaches on Defects4J Dataset}

\begin{table}[t]
  \caption{RQ1. Comparison Results with DL-based APR Approaches on Defects4J \underline {without Fault Localization}.}
  \vspace{-6pt}
  {\small
			\begin{center}
				\renewcommand{\arraystretch}{1}
				\begin{tabular}{p{0.8cm}<{\centering}|p{1.2cm}<{\centering}|p{0.9cm}<{\centering}|p{1cm}<{\centering}|p{0.8cm}<{\centering}|p{0.8cm}<{\centering}|p{0.8cm}<{\centering}}
					
					\hline
					&\textbf{SequenceR}&\textbf{DLFix}& \textbf{CocoNut}&\textbf{CURE}&\textbf{CURE*}&\textbf{\tool}\\
					\hline
					Chart  & 4/5   & 7/13  & 8/17  & 7/18  & 9/20  & 9/18\\
					Closure& 5/7   & 7/12  & 7/14  & 9/21 & 11/19  & 12/18\\
					Lang   & 2/2   & 6/15  & 6/16  & 7/12 & 8/18  & 9/16\\
					Math    & 8/11  & 18/28 & 20/31 & 21/33 & 21/35 & 22/34\\
					Mockito & 0/0   & 1/1   & 2/3   & 2/3  &2/4  & 2/4\\
					Time    & 0/0   & 1/3   & 2/4   & 3/5  &3/7  & 3/6\\
					\hline
					Total   & 19/25 & 40/72 & 44/85 & 48/92 & 54/103 & 56/96\\
					\hline
					P(\%)  & 76.0  & 55.6  & 51.8  & 52.2  &  53.4 & 58.3\\
					\hline
				\end{tabular}
			{\footnotesize{
				Note: P is the probability of the generated plausible patches to be correct. In the cells, x/y: x means the number of correct fixes and y means the number of candidate patches that can pass all test cases. CURE: 5-hour limit of validation, CURE*: 5,000 candidates.}}

%                               For example, for \tool, 96 candidate patches can pass all test cases, but only 56 of them match with developers' fixes.}}
%                                However, 56 out of 96 are the correct fixes compared with the fixes by developers in the ground truth.}}
%			{\color{red}{CURE: the cure approach with 5 hours limitation per bug which is the same setting as our \tool. CURE*: the cure approach with their own setting that validating the top 5,000 candidate patches per bug}}
				\label{RQ1_defect4j}
			\end{center}
                }
		\end{table}

\subsubsection{{\bf Without Fault Localization}}

{\em {\tool} fixes more bugs than DL-based baselines}. {\tool}
auto-fixes 56 bugs, i.e., 194.7\% (37 bugs), 40\% (16), 27.3\% (12),
16.7\% (8), and 3.7\% (2) more bugs than Sequen\-ceR, DLFix, CoCoNuT,
CURE, and CURE*, respectively (Table~\ref{RQ1_defect4j}).

With the 5-hour limit, {\tool} generates {\em the most correct (56)
  and the most plausible patches (96)} than other baselines.  {\tool}
also has a {\em higher percentage of the generated plausible patches
  to be correct than all the baselines}, except SequenceR.
%with 5-hour limit.
However, {\tool} can fix 194\% more bugs and 6 times more plausible
patches than SequenceR.
%With the time limit,
{\tool} also fixed 3 bugs that all the DL-based baselines missed.


CURE*, with the cut-off setting, ranked 10,000 candidates and refined
the ranking to pick and validate top 5,000 candidates. Despite taking
more time of patch validation (about 5.5 hours on average for
validating those 5,000 candidates), CURE* fixed 2 bugs less than
{\tool}. However, with the same setting of 5-hour limit, {\tool} fixes
16.7\% (8 bugs) more than CURE. Moreover, {\tool} fixed 12 bugs that
CURE missed; and CURE fixed only 4 bugs that {\tool} missed.

%In comparison with CURE and CURE*, CURE* ranked 10,000 candidates and
%refined the ranking to pick and validate top 5,000 candidates. Despite
%taking more time of patch validation (about 5.5 hours), CURE* fixed 2
%bugs less than {\tool}. However, with the same setting of 5-hour
%limit, {\tool} fixes 16.7\% (8 bugs) more than CURE. Moreover, {\tool}
%fixed 12 bugs that CURE missed; and CURE fixed only 4 bugs that
%{\tool}~missed.

%Despite costing more than double time (>10 hours of validation), CURE*
%fixed 2 bugs less than {\tool}. With 5-hour limit, if CURE did not
%identify a plausible patch, on average, it validated 2,350
%candidates. Importantly, {\tool} fixes 16.7\% (8 bugs) more than CURE
%with the same 5-hour limit. Moreover, {\tool} fixed 12 bugs that CURE
%missed; and CURE fixed 4 bugs that {\tool}~missed.

\vspace{-6pt}
\subsubsection{{\bf With Fault Localization}}

Table~\ref{RQ1_defects4J_with_FL} shows the comparison result on
Defects4J with an FL tool. As seen, due to the FL tool, the
performance of all models decreases due to the confounding
inaccuracy. However, {\tool} can still fix more bugs than any
baseline. It automatically fixes 44 bugs, i.e., 193.3\% (29 bugs),
46.7\% (14), 33.3\% (11), 22.2\% (8), and 10\% (4) more bugs than the
baselines SequenceR, DLFix, CoCoNuT, CURE, and CURE*,
respectively. With 5-hour limit, {\tool} fixed the most correct (44)
and the most plausible (77) patches. Moreover, with that limit,
{\tool} fixed 9 bugs that CURE missed; and CURE fixed only 3 bugs that
{\tool} missed. {\tool} fixed 2 bugs that all the DL-based baselines
missed. Compared with CURE* with the cut-off setting, {\tool} takes
10\% less time (0.5 hours less on average), but fixed 4 more bugs than
CURE*.


%^CURE* costs more than double validation
%time, but fixed 4 bugs less than {\tool}.

%Furthermore, {\tool} generates the most plausible patches (i.e., {\bf
%  XX}) among all the models.  It also has a higher percentage of the
%generated plausible patches to be correct than all the
%baselines. Moreover, CDFix fixed {\bf 9} bugs that the {\em best
%  baseline} CURE missed; and CURE fixed {\bf 3} bugs that CDFix
%missed. CDFix fixed {\bf 2} bugs that all the DL-based baselines
%missed.

%
%Note that the numbers for DLFix are different from those
%reported in DLFix paper~\cite{icse20}. The reason is that DLFix's
%authors had filtered from the datasets the multiple-line bugs due to
%DLFix's limited capabability. We used the full datasets with all the
%bugs.

%Tien
%The reason for the difference between the results for DLFix in this paper and those reported in DLFix’s paper_[18] is that in DLFix’s experiment, the authors filtered from the datasets to keep only the single-line bugs for the comparison with other baselines. In CDFix, we used the full datasets with multiple-line bugs. Thus, the results reported in this paper are lower. The same reason is for other baselines.




%}}




\begin{table}[t]
  \caption{RQ1. Comparison Results with DL-based APR Approaches on Defects4J \underline {with Fault Localization}.}
  \vspace{-6pt}
  {\small
			\begin{center}
				\renewcommand{\arraystretch}{1}
				\begin{tabular}{p{0.8cm}<{\centering}|p{1.2cm}<{\centering}|p{0.9cm}<{\centering}|p{1cm}<{\centering}|p{0.8cm}<{\centering}|p{0.8cm}<{\centering}|p{0.8cm}<{\centering}}
					
					\hline
					&\textbf{SequenceR}&\textbf{DLFix}& \textbf{CocoNut}&\textbf{CURE}&\textbf{CURE*}&\textbf{\tool}\\
					\hline
					Chart  & 3/3   & 5/12  & 6/11  & 6/13  & 6/15 & 7/16\\
					Closure& 4/5   & 6/10  & 6/9   & 6/10  & 7/14 & 9/15\\
					Lang   & 2/2   & 5/12  & 5/13  & 5/14  & 6/14  & 7/13\\
					Math    & 6/9  & 12/18 & 13/21 & 16/23 & 17/30 & 18/27\\
					Mockito & 0/0   & 1/1   & 2/2   & 2/2  & 2/3  & 2/3\\
					Time    & 0/0   & 1/2   & 1/1   & 1/2  & 2/3  & 1/3\\
					\hline
					Total   & 15/19 & 30/55 & 33/57 & 36/71 & 40/79 & 44/77\\
					\hline
					P(\%)  & 68.4  & 54.5  & 57.9  & 50.7  & 50.6  & 57.1\\
					\hline
				\end{tabular}
				\label{RQ1_defects4J_with_FL}
			\end{center}
                }
		\end{table}















%========================================end ===========================


\iffalse
{\footnotesize{
		\begin{table}[t]
			\caption{RQ1. Comparison with the Pattern-based APR Baselines on Defect4J.}
			\begin{center}
				\renewcommand{\arraystretch}{1}
				\begin{tabular}{p{0.8cm}<{\centering}|p{0.6cm}<{\centering}|p{1.1cm}<{\centering}|p{0.8cm}<{\centering}|p{1cm}<{\centering}|p{0.6cm}<{\centering}|p{0.8cm}<{\centering}}
					
					\hline
					&\textbf{Tbar}&\textbf{SequenceR}&\textbf{DLFix}& \textbf{Coconut}&\textbf{CURE}&\textbf{\tool}\\
					\hline
					Chart  & 11/13  & 4/5   & 7/13  & 8/13  & 7/12   & 9/12\\
					Closure& 17/26  & 5/7   & 7/12  & 7/18  & 9/27   & 12/24\\
					Lang   & 13/18  & 2/2   & 6/15  & 6/16  & 7/12   & 9/16\\
					Math   & 22/35  & 8/11  & 18/28 & 20/31 & 21/33  & 22/34\\
					Mockito& 3/3    & 0/0   & 1/1   & 2/3   & 2/3    & 2/4\\
					Time   & 3/6    & 0/0   & 1/3   & 2/4   & 3/5    & 3/6\\
					\hline
					Total  & 69/101 & 19/25 & 40/72 & 44/85 & 48/92  & 56/96\\
					\hline
					P(\%)  & 68.3   & 76.0  & 55.6  & 51.8  & 52.2   & 58.3\\
					\hline
				\end{tabular}
				Note: P is the probability of the generated plausible patches to be correct.\\
				In the cells, x/y: x means the number of correct fixes and y means the number of candidate patches that can pass all test cases. For example, for \tool, 96 candidate patches can pass all test cases. However, 56 out of 96 are the correct fixes compared with the fixes in the ground truth.
				\label{RQ1_defect4j}
			\end{center}
		\end{table}
}}
\fi
