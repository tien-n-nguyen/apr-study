\section{Introduction}

%Fixing software defects is one of the crucial maintenance
%activities. Thus,

%Detecting and fixing software defects is one of the most crucial
%activities in software development.
Several researchers have developed the approaches to automate the
process of fixing software defects. The approaches that help
developers automatically fix a software defect in a program is
referred to as {\em automated program repair} (APR). The APR
approaches can be broadly classified in the following categories
according to their techniques:
%Researchers have proposed several approaches to help developers in
%automatically identifying and fixing the defects in programs. Such
%approaches are referred to as {\em automated program~repair}
%(APR). The APR approaches have been leveraging various techniques in
%the areas of
{\em search-based software engineering}, {\em software mining}, {\em
  machine learning (ML)}, and {\em deep learning (DL)}.

In search-based
approaches~\cite{LeGoues-icse12,le2011genprog,martinez2016astor,qi2014strength},
the buggy code is first mutated via certain operators to produce the
potential solution space. Then, a search strategy is designed to find
the fix in the solution space. Instead searching for a solution, the
software mining-based APR models aim to learn the fixing patterns from
the prior bug
fixes~\cite{kim2013automatic,le2016history,liu2019avatar,tbar-issta19,nguyen2013semfix,
  icse10,ray-fse12}. Some mining-based approaches learn the patterns
from the source code~\cite{liu2019avatar,tbar-issta19} and others
learn them from prior bug-fixing
changes~\cite{wen2018context,Simfix,koyuncu2018fixminer}.  The fixing
patterns/templates could be mined automatically from the repositories
or pre-defined via semi-automated
techniques~\cite{le2016history,nguyen2013semfix,liu2019avatar,tbar-issta19}.

%Recent advances in
Machine learning (ML)
%enable several models to
has facilitated implicit learning from prior bug fixes to apply to repair
the current buggy
code~\cite{long2016automatic,long2017automatic,saha2017elixir}.
%They derive the candidate fixes and rank them according to their
%likelihoods
%researchers have leveraged deep learning (DL) to automatically derive
%the fixing changes to a given buggy code. Some
Some Deep Learning (DL)-based approaches learn the fix from prior {\em
  similar bug fixes and/or
  patterns}~\cite{gupta2017deepfix,white2019sorting,white2016deep}.
Other DL-based approaches treat APR as {\em machine translation} from
a buggy version to a correct one using transformers and other
models~\cite{chakrabortycodit,chen2018sequencer,hata2018learning,tufano2018empirical,see2017get}. Instead
of treating APR as machine translation, other DL-based approaches aim
to implicitly learn the {\em transformation rules} from a buggy code
to a correct one accordingly to the surrounding {\em context} of the
transformations~\cite{chen2018sequencer,icse20,cure-icse21,lutellier2020coconut}.
Those approaches show that {\em learning bug-fixing changes needs to
  be dependent on {\em code context}}. For example, in
C~code, if the preceding context contains \code{fopen} as in
\code{FILE *fd = fopen (fname, ``rb'');}, the succeeding
bug-fixing code is more likely to be \code{if (fd != null)} or
\code{if (fd == null)}. However, if the preceding context contains
\code{fread} as in \code{n = fread(buffer,1,size,fd);}, the
succeeding bug-fix is more likely to be \code{if (n != size)} or
\code{if (n == size)}, rather than a null check \code{if (n != null)}.
Those context-aware models have achieved better performance in
APR~\cite{icse20,lutellier2020coconut,cure-icse21}.

%For example, a {\em null check} is needed after a call to read data
%from a socket with \code{BufferedReader.readline} to make sure a
%successful data retrieval.
%tufano2019learning,chakrabortycodit}.

Despite recognizing the importance of contexts in learning the fixes,
the existing DL-based APR approaches still have limitations in
integrating contextual information in the APR
process. \underline{First}, the DL-based APR approaches that learn
from {\em bug-fixing patterns}~\cite{white2016deep,gupta2017deepfix}
have focused on similar code and/or code changes with {\em little or
  no consideration} on whether those code or fixing patterns appear in
certain surrounding contexts. \underline{Second}, some DL-based APR
approaches aim to learn {\em only the code changes} for fixes, e.g.,
from a buggy subtree in an Abstract Syntax Tree (AST) or a buggy
statement to the correct subtree or correct
statement~\cite{chakrabortycodit,see2017get}. In this treatment, too
little or no context might not help a model learn the fixes that depend on a
larger surrounding code.

\underline{Third}, in contrast, other
approaches~\cite{hata2018learning,tufano2019learning,tufano2018empirical}
follow the machine translation direction to take the entire buggy
method and translate it to the correct one, while the fix might be
only a small editing change to a single statement. Those
translation-based approaches {\em do not distinguish clearly the
  boundary} of the fixing change (e.g., to a buggy statement) and the
surrounding context (e.g., the preceding or succeeding code). Due to
the mixture of fixing changes and context, those translation models or
transformers could pick the incorrect locations for fixing, because
they might not learn what fixing changes are appropriate in specific
contexts~\cite{icse20}. \underline{Fourth}, some other DL-based
approaches have separate representations for
contexts~\cite{chen2018sequencer,cure-icse21,lutellier2020coconut}.
They extract features in the surrounding context to be fed into a DL
model to learn to fix.

\underline{Fifth}, dedicating a separate model for context learning
has recently been shown to improve over the DL-based APR approaches
with a single DL model~\cite{icse20}. In DLFix~\cite{icse20}, the
first layer is a tree-based RNN model that learns the contexts of bug
fixes (CCL) and its result is used as an additional weighting input
for the second layer designed to learn the bug-fixing code
transformations (CTL). However, the cascading architecture from CCL
$\rightarrow$ CTL creates a {\em confounding effect} from the inaccuracy of
the learning of the context to the learning of the bug-fixing
transformations. Moreover, {\em the equally important impact from CTL to
CCL is not considered}. Such impact from the direction of CTL
$\rightarrow$ CCL, could help the model correctly learn the context,
leading to better code-transformation learning for context-dependent
bugs. In the previous example, if the bug fix is a change from
\code{if (fd == null)} into \code{if (fd != null)}, the preceding
context more likely contains \code{fopen(...)} than \code{fread(...)}.

%For example, in the EVP library (OpenSSL), \code{EVP$\_$VerifyInit},
%\code{EVP$\_$VerifyUpdate}, and \code{EVP$\_$VerifyFinal} are called
%in that order. The last function returns 3 values: 1 for correct
%signature verification, 0 for incorrect verification, and -1 for a
%failure in verification.  The last case has been overlooked by a few
%systems, thus, their developers have often fixed the code from
%\code{if (!EVP$\_$VerifyFinal(...))}  into \code{if
%  (EVP$\_$VerifyFinal(...) <=0)}. When such fixing is encountered, the
%boundary of the context is likely to be set so that it contains the
%calls \code{EVP$\_$VerifyInit} and \code{EVP$\_$VerifyUpdate}.




%the DL-based APR approaches that leverage {\em machine translation or
%  transformers}~\cite{chakrabortycodit,hata2018learning,tufano2018empirical,see2017get}
%often take too little surrounding code as context to learn fixing
%changes or do not have a clear boundary of the fixing changes and the
%context. Let us elaborate this point. Some DL-based APR approaches aim
%to learn {\em only the code changes} for a fix, e.g., from one buggy
%subtree in an Abstract Syntax Tree (AST) or a buggy statement to the
%correct subtree or statement~\cite{chakrabortycodit}. In this
%treatment, too little context might not help a model learn the fixes
%that depend on a larger surrounding code. In contrast, other
%approaches~\cite{chen2018sequencer,hata2018learning} take the entire
%buggy method and translate it to the correct one, while the fix might
%be only a small editing change to a single statement. Those
%translation-based approaches {\em do not distinguish clearly the
%  boundary} of the fixing change (e.g., to a buggy statement) and the
%surrounding context (e.g., the preceding or succeeding code). Due to
%the mixture of fixing changes and context, those machine translation
%models or transformers might not learn what fixing changes are
%appropriate in specific contexts~\cite{icse20}.

%===============================================
%\underline{Third}, to address that issue, DLFix~\cite{icse20} makes a
%clear boundary of fixing changes and the surrounding context, and
%dedicates two layers for those two tasks. The first layer is a
%tree-based RNN model that learns the contexts of bug fixes and its
%result is used as an additional weighting input for the second layer
%designed to learn the bug-fixing code transformations. However, the
%cascading architecture in DLFix from the two layers create a
%confounding effect from the inaccuracy of the learning of the context
%to the learning of the bug-fixing code transformations.
%---------------------------------

%We conjecture that the two tasks of learning the code
%context and learning the bug-fixing code transformations are related
%and dependent on each other. {\bf Correct learning of contexts can
%  benefit the learning of code transformations and vice versa in
%  automated program repair}. For example, in C code, if the
%preceding code (i.e., part of the context) contains \code{fopen} as in
%\code{FILE *fd = fopen (fname, ``rb'');}, then the succeeding
%bug-fixing code is more likely to be \code{if (fd != null)} or
%\code{if (fd == null)}. However, if the preceding code contains
%\code{fread} as in \code{n = fread(buffer,1,size,fd);}, then the
%succeeding bug-fix is more likely to be \code{if (n != size)} or
%\code{if (n == size)}, rather than a null check \code{if (n !=
%  null)}. In contrast, if the bug fix is a
%change from \code{if (fd == null)} into \code{if (fd != null)}, then the
%preceding code more likely contains \code{fopen} than \code{fread}.
%Let us call such relation between two tasks as {\em duality}.

%{\bf Correct learning of contexts can benefit the learning of code
%  transformations and vice versa in automated program repair}

We introduce {\tool}, a context-aware dual-task learning APR approach,
that {\em explicitly models the mutual impact of context learning and
  code transformation learning in both directions}. We train the two
models simultaneously with soft-sharing parameters to exploit the
duality of CCL and CTL. Specifically, we use a model called {\em
  cross-stitch unit}~\cite{misra2016cross} that connects CTL and
CCL. The sharing of representations between CCL and CTL is modeled by
learning a linear combination of the input features from two
models. Cross-stitch unit helps regularize both CCL and CTL by
learning and enforcing shared representations by combining feature
maps. This joint training enables the dual-task learning to propagate
the impact of CCL and CTL and vice~versa. With the dual-task learning
solution, {\tool} has two key departure points to address the
limitations of the existing DL-based APR approaches: {\bf 1) it models
  both directions of the mutual impacts of CCL and CTL; 2) it
  overcomes the confounding effect in the existing cascading
  architecture}.

In {\tool}, for training, the input for the CCL model is the Abstract
Syntax Tree (AST) of a buggy method and that of the fixed method, and
the input of the CTL model is the AST subtree of each of its buggy
statements, and that of the respective fixed statement. For
auto-fixing, a buggy statement to be fixed is identified by a fault
localization tool. Then, the AST subtree for the buggy statement is
fed into the trained CTL model to produce the candidate patches. We
design a novel tree-oriented beam search for efficiency. Finally, the
candidate patches are ranked and validated via test cases.

We conducted several experiments to evaluate and compare {\tool} with
the DL-based APR models on three large datasets:
Defects4J~\cite{defects4j} (395 bugs), Bugs.jar~\cite{saha2018bugs}
(1,158 bugs), and BigFix~\cite{yioopsla19} (+4.9M methods and 1.8M
buggy ones).
%We compared {\tool} against several state-of-the-art DL-based APR
%approaches.
Our results show that {\tool} can fix 12.1\% and 14.6\% more bugs than
the best-performance DL-based model, CURE~\cite{cure-icse21}, using
only the Top-1 patches, in the large datasets Bugs.jar and BigFix,
respectively. Additionally, {\tool} fixed 89 and 45 unique bugs that
CURE missed, while {\tool} missed only 50 and 27 bugs that were fixed
by CURE in Bugs.jar and BigFix, respectively.  Furthermore, in
Defects4J, {\tool} can fix 8 more bugs than the best-performance
DL-based model, CURE~\cite{cure-icse21}. In Defects4J, {\tool} fixes
194.7\%, 40\%, 27.3\%, and 16.7\% more bugs than the baselines:
SequenceR~\cite{chen2018sequencer}, DLFix~\cite{icse20},
CoCoNuT~\cite{lutellier2020coconut}, CURE~\cite{cure-icse21},
respectively. The contributions of this paper are listed as follows:

%{\bf A. DL for APR:} {\tool} is the first DL APR that generates
%comparable and complementary results with powerful pattern-based
%tools, as recently published DL-based APR can only fix very few bugs
%on Defects4J. {\tool} helps confirm that further research on building
%advanced DL to improve APR is promising and valuable.

{\bf A. A Novel Dual-Task Learning DL-based APR Model:}

1) First APR approach {\em leveraging dual-task learning to propagate
  the mutual impacts of context learning and transformation learning
  in both directions} to improve APR performance.

2) Advancing DL-based APR approaches with dual-task learning
to avoid confounding inaccuracies from cascading architecture.

%A context-aware APR approach that leverages dual learning {\em to
%  propagate the impact between context learning and bug-fixing code
%  transformation learning to improve APR}. We {\bf advance DL-based
%  APR} with {\bf explicit modeling of the impact of contexts} via {\bf
%  dual learning}.

%{\bf B. Dual Learning Technique for Context Learning.} to explicitly
%model the context and

%with the use of a dual learning scheme that exploits the duality of
%learning bug-fixing code transformations and learning code contexts to
%improve APR performance.

{\bf B. Empirical Results:} (Code and data are
published~\cite{CDFix2022}).
%{\bf Advancing DL-based APR approaches with dual-task learning for CCL
%  and CTL}:
%Extensive experiments were performed to evaluate different aspects
%of {\tool} and comparison.
%We evaluated {\tool} against the DL-based models to show that it can
%fix more bugs than those approaches.
Experiments show {\tool}'s improvements over prior
DL-based APRs.

%to evaluate {\tool} and show it improves
%APR performance over the existing DL-based approaches.

%{\bf B. Empirical Results:} (Code and data are published~\cite{CDFix2022}).
%{\bf Improving over all the DL-based APR approaches}: we evaluated
%{\tool} against the most recent DL-based models to show that it can
%auto-fix more bugs than those state-of-the-art approaches.

%{\tool} is able to detect 2.5 times more bugs than the best performing
%baseline.  {\tool} can fix 253 new bugs (out of 1158 in Bugs.jar) than
%all the other DL-based APR techniques combined.

%-------------------------------------------------------------

%{\bf 1. {\tool}: Novel DL-based fault localization approach} that
%derives the co-change fixing locations for a bug. Our idea is
%to treat such problem as a dual learning task with the joint training
%of the method-level and statement-level co-fixing learning models.

%{\bf 2. Novel graph-based representation learning with co-change
%  statements.} Our graph-based representation learning with GCN
%and the novel type of features in co-change statements enables
%the dual-task models learn derive co-change fixing locations.

%{\bf 3. Extensive empirical evaluation.} We evaluated {\tool} against
%the most recent FL models to show our model's better performance. Our
%replication package is available at~\cite{FixLocator2022}.
