\section{Motivating Example}
\label{motiv:sec}

\subsection{An Example and Observations}

\begin{figure}[t]
	\centering
	\lstset{
		numbers=left,
		numberstyle= \tiny,
		keywordstyle= \color{blue!70},
		commentstyle= \color{red!50!green!50!blue!50},
		frame=shadowbox,
		rulesepcolor= \color{red!20!green!20!blue!20} ,
		xleftmargin=1.5em,xrightmargin=0em, aboveskip=1em,
		framexleftmargin=1.5em,
                numbersep= 5pt,
		language=Java,
    basicstyle=\scriptsize\ttfamily,
    numberstyle=\scriptsize\ttfamily,
    emphstyle=\bfseries,
                moredelim=**[is][\color{red}]{@}{@},
		escapeinside= {(*@}{@*)}
	}
	\begin{lstlisting}[]
    public LegendItemCollection getLegendItems() {
        LegendItemCollection result = new LegendItemCollection();
        if (this.plot == null) {
            return result;
        }
        int index = this.plot.getIndexOf(this);
        CategoryDataset dataset = this.plot.getDataset(index);
(*@{\color{red}{-\quad \quad \quad if (dataset != null) {}@*)
(*@{\color{cyan}{+\quad \quad \quad if (dataset == null) {}@*)
            return result;
        }
        int seriesCount = dataset.getRowCount();
        // update result
        ...
        return result;
    }
	\end{lstlisting}
        \vspace{-15pt}
        \caption{Mutual Impact between Context and Fixing Change}
        \vspace{-8pt}
        \label{fig:motiv}
\end{figure}

%       if (plot.getRowRenderingOrder().equals(SortOrder.ASCENDING)) {
%            for (int i = 0; i < seriesCount; i++) {
%                if (isSeriesVisibleInLegend(i)) {
%                    LegendItem item = getLegendItem(index, i);
%                    if (item != null) {
%                        result.add(item);
%                    }
%                }
%            }
%        }
%        else {
%            for (int i = seriesCount - 1; i >= 0; i--) {
%                if (isSeriesVisibleInLegend(i)) {
%                    LegendItem item = getLegendItem(index, i);
%                    if (item != null) {
%                        result.add(item);
%                    }
%                }
%            }
%        }

Let us start with a real-world example to motivate our approach.
Figure~\ref{fig:motiv} shows a real bug from the project \code{Chart}
in the Defects4J dataset. The bug occurred at line 8 in which the
condition for stopping the updating process on the \code{result}
variable is incorrect (\code{if (dataset != null)}). The result is
returned only when the dataset (line 7) is empty. Thus, it was fixed
into \code{if (dataset == null)}.

\noindent {\bf Observation 1 [Fixing Change Depends on
    Context]}. As seen, the bug-fixing change from line 8 to
line 9 (\code{if (dataset != null)} $\rightarrow$ \code{if (dataset ==
  null)}) depends on the surrounding code context. On line 7, the
dataset is retrieved via \code{getDataset}. According to the logic of
the program, the result is returned when \code{dataset} is
\code{null}.  Thus, the incorrect checking was fixed into line 9. That
is, that fix (rather than \code{if (dataset == 0)}) makes sense in
the context of \code{getDataset} as well as the other code such as
\code{getIndexOf}, \code{LegendItemCollection}, and the succeeding
code (\code{dataset.getRowCount}, \code{return result}, etc.).

\noindent {\bf Observation 2 [Context Depends on Fixing
    Change]}. Because of the change (\code{if (dataset != null)}
$\rightarrow$ \code{if (dataset == null)}), the key features in the
context could likely be \code{getDataset} and \code{getIndexOf},
rather than \code{this.plot == null} (line 3) or \code{return result;}
(line 4).

Despite their successes, the state-of-the-art DL-based APR approaches
are still limited in integrating the contextual information.

\underline{First}, for the DL-based approaches that learn the fixes
from prior {\em similar bug fixes or
  patterns}~\cite{gupta2017deepfix,white2019sorting,white2016deep},
there might not be any fix similar to the one in
Figure~\ref{fig:motiv}. They focus on similar bug fixes with little or
no consideration on whether a fix appears in certain~context.

\underline{Second}, some other DL-based APR approaches focus {\em only
  on learning the changes} to fix an AST subtree or a
statement~\cite{chakrabortycodit,see2017get} without considering the
context. For this example, without examining the surrounding context,
e.g., the preceding code \code{getDataset} or the succeeding code
\code{getRowCount} or \code{return result}, such a model will
make the same change regardless of contexts.
%not likely learn to change line 8 into line 9.

%hata2018learning,tufano2019learning,tufano2018empirical

\underline{Third}, for the machine translation and transformer-based
APR
models~\cite{hata2018learning,tufano2019learning,tufano2018empirical},
the entire method in Figure~\ref{fig:motiv} is used as the input. {\em
  Without distinguishing the boundary of the context and the fixing
  changes}, such a model faces the noise, i.e., the code irrelevant to
the actual fix at lines 8--9. For example, the code at lines 2--5 on
the legends is not crucial for the fix regarding the dataset at line
9. Thus, such a model could identify the incorrect location to fix.

\underline{Fourth}, some other DL-based approaches have separate
representations for
contexts~\cite{chen2018sequencer,cure-icse21,lutellier2020coconut}.
SequenceR~\cite{chen2018sequencer},
CoCoNuT~\cite{lutellier2020coconut}, and CURE~\cite{cure-icse21}
extract features in the surrounding context (e.g., lines 2--7, lines
10--15) to be fed into a DL model to learn to fix.
%These approaches utilize only one DL model for learning the fixes
%using the features extracted from the contexts.

%\underline{Finally}, recent DL-based APR
%approaches~\cite{icse20,cure-icse21} have leveraged the context to
%help better fix a bug. They separately consider the surrounding code
%as the context (e.g., lines 2--7, lines 10--15).

\underline{Fifth}, a recent trend shows that
%DLFix~\cite{icse20} shows that
dedicating a separate model for context learning can achieve better
performance than using a single
model~\cite{icse20}. DLFix~\cite{icse20} has two models in which one
tree-based LSTM model learns the context and another one learns the
code transformation (e.g., from line 8 to line 9). It cascades the
first LSTM model to the second one in which the output of the model
for contexts is used as a weight for the transformation learning one.
Thus, DLFix~\cite{icse20} suffers two limitations: 1) it does not
capture well both directions of the mutual impact between two types of
learning (esp. from bug-fixing learning to context learning), 2) it
creates confounding inaccuracies as explained.
%
%This cascading architecture creates a confounding effect from the
%inaccuracy of the learning of the context to the learning of the
%transformations.
In Section~\ref{sec:overlap}, we will present our study and examples
to illustrate this.

%those limitations of the existing DL-based APR approaches.

\subsection{Key Idea}
\label{sec:key-idea}

%To address the above issue with the cascading architecture,



To advance DL-based APR, we {\bf {\em explicitly model both directions
    of the mutual impact between context learning and transformation
    learning}}. We design {\tool} that treats context learning and
transformation learning as a dual task with code context learning
model (CCL) and code transformation learning (CTL).

%{\tool} consists of two models. The first model, CCL, is dedicated to
%learn \underline{c}ode \underline{c}ontexts, and the second model,
%CTL, to learn bug-fixing \underline{c}ode \underline{t}ransformations.


%To avoid the confounding effect in a naive solution of detecting buggy
%methods first and then detecting buggy statements in those methods, we
%design an approach that treats detecting dependent CC fixing locations
%as a {\em dual learning} task between them. First, the {\em
%  method-level FL} model (\code{MethFL}) aims to learn the methods
%that need to be modified in the same fix. Second, the {\em
%  statement-level FL} model (\code{StmtFL}) aims to learn the
%co-fixing statements regardless of whether they are in the same or
%different methods.

Intuitively, the two models CCL and CTL are dependent on each
other. The learning of the contexts can benefit the learning of
bug-fixing transformations and vice versa. We refer to this relation
as {\em duality}, which can provide some useful constraints for
{\tool} to learn to fix context-dependent bugs. We conjecture that the
join training of the two models can improve the performance of both
models, if we can achieve the shared representations. For example, in
Figure~\ref{fig:motiv}, if the context is observed as containing
\code{getDataset} at line 7, \code{getIndexOf} at line 6, and
\code{return result} at line 10, the likelihood of the fixing change
at line 8 becoming \code{(dataset == null)} is more than that of
\code{(dataset != 0)}. The rationale is that only if the retrieved
data is empty, the result is returned. On the other hand, if the
bug-fixing transformation is observed as \code{(dataset != null)}
becoming \code{(dataset == null)}, it is likely to have an assignment
\code{dataset = ...;} in the context preceding \code{(dataset != null)}.
Therefore, in {\tool}, we joinly train CTL for context learning and
CCL for transformation learning with soft-sharing of parameters to
exploit their relation.

Specifically, {\bf {\em we use a cross-stitch unit~\cite{misra2016cross} to
  connect CTL and CCL}}. The sharing of representations between them is
modeled by the learning a linear combination of the input features
from two models. Cross-stitch unit helps regularize both CCL and CTL
by learning and enforcing shared representations by combining feature
maps. This joint training {\em propagates the mutual impact} of context
learning and transformation learning. {\em The cross-stitching also helps
avoid confounding inaccuracies} in the cascading architecture.

%and vice versa, to improve APR performance.
