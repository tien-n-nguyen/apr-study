\section{Motivating Example}
\label{motiv:sec}

\subsection{An Example and Observations}

\begin{figure}[t]
	\centering
	\lstset{
		numbers=left,
		numberstyle= \tiny,
		keywordstyle= \color{blue!70},
		commentstyle= \color{red!50!green!50!blue!50},
		frame=shadowbox,
		rulesepcolor= \color{red!20!green!20!blue!20} ,
		xleftmargin=1.5em,xrightmargin=0em, aboveskip=1em,
		framexleftmargin=1.5em,
                numbersep= 5pt,
		language=Java,
    basicstyle=\scriptsize\ttfamily,
    numberstyle=\scriptsize\ttfamily,
    emphstyle=\bfseries,
                moredelim=**[is][\color{red}]{@}{@},
		escapeinside= {(*@}{@*)}
	}
	\begin{lstlisting}[]
    public LegendItemCollection getLegendItems() {
        LegendItemCollection result = new LegendItemCollection();
        if (this.plot == null) {
            return result;
        }
        int index = this.plot.getIndexOf(this);
        CategoryDataset dataset = this.plot.getDataset(index);
(*@{\color{red}{-\quad \quad \quad if (dataset != null) {}@*)
(*@{\color{cyan}{+\quad \quad \quad if (dataset == null) {}@*)
            return result;
        }
        int seriesCount = dataset.getRowCount();
        // update result
        ...
        return result;
    }
	\end{lstlisting}
        \vspace{-15pt}
        \caption{Bug-Fixing Change Depends on Context}
        \vspace{-8pt}
        \label{fig:motiv}
\end{figure}

%       if (plot.getRowRenderingOrder().equals(SortOrder.ASCENDING)) {
%            for (int i = 0; i < seriesCount; i++) {
%                if (isSeriesVisibleInLegend(i)) {
%                    LegendItem item = getLegendItem(index, i);
%                    if (item != null) {
%                        result.add(item);
%                    }
%                }
%            }
%        }
%        else {
%            for (int i = seriesCount - 1; i >= 0; i--) {
%                if (isSeriesVisibleInLegend(i)) {
%                    LegendItem item = getLegendItem(index, i);
%                    if (item != null) {
%                        result.add(item);
%                    }
%                }
%            }
%        }

Let us start with a real-world example to motivate our approach.
Figure~\ref{fig:motiv} shows a real bug from the project \code{Chart}
in the Defects4J dataset. The bug occurred at line 8 in which the
condition for stopping the updating process on the \code{result}
variable is incorrect (\code{if (dataset != null)}). The result is
returned only when the dataset (line 7) is empty. Thus, it was fixed
into \code{if (dataset == null)}.

\noindent {\bf Observation [Bug-Fixing Change Depends on Context]}. We
can see that the bug-fixing change from line 8 to line 9 (\code{if
  (dataset != null)} $\rightarrow$ \code{if (dataset == null)})
depends on the surrounding code context. On line 7, the dataset is
retrieved via \code{getDataset}. According to the logic of the
program, the result is returned when \code{dataset} is \code{null}.
Thus, the incorrect checking was fixed into line 9. That is, that fix
makes sense in the context of the appearance of \code{getDataset} as
well as the other code such as \code{getIndexOf},
\code{LegendItemCollection}, and the succeeding code
(\code{dataset.getRowCount}, \code{return result}, etc.).

Despite their successes, the state-of-the-art DL-based APR approaches
are still limited in integrating the contextual information.

\underline{First}, for the DL-based approaches that learn the
fixes from prior {\em similar bug fixes or
  patterns}~\cite{gupta2017deepfix,white2019sorting,white2016deep},
there might not be any similar fix to the one in
Figure~\ref{fig:motiv}. In general, they focus on similar bug fixes
with little or no consideration on whether a fix appears in certain
context.

\underline{Second}, some other DL-based APR approaches focus {\em only
  on learning the changes} to fix an AST subtree or a
statement~\cite{chakrabortycodit,see2017get} without considering the
context. For this example, without examining the surrounding context,
e.g., the preceding code \code{getDataset} or the succeeding code
\code{getRowCount} or \code{return result}, such a model will not
likely learn to change line 8 into line 9.

%hata2018learning,tufano2019learning,tufano2018empirical

\underline{Third}, for the machine translation and transformer-based
APR
models~\cite{hata2018learning,tufano2019learning,tufano2018empirical},
the entire method in Figure~\ref{fig:motiv} is used as the input. {\em
  Without distinguishing the boundary of the context and the fixing
  changes}, such a model faces the noise, i.e., the code irrelevant to
the actual fix at lines 8--9. For example, the code at lines 2--5 on
the legends is not crucial for the fix regarding the dataset at line
9. Thus, such a model could identify the incorrect location to fix.

\underline{Fourth}, some other DL-based approaches have separate
representations for
contexts~\cite{chen2018sequencer,cure-icse21,lutellier2020coconut}.
SequenceR~\cite{chen2018sequencer},
CoCoNuT~\cite{lutellier2020coconut}, and CURE~\cite{cure-icse21}
extract features in the surrounding context (e.g., lines 2--7, lines
10--15) to be fed into a DL model to learn to fix. These approaches
utilize only one DL model for learning the fixes using the features
extracted from the contexts.

%\underline{Finally}, recent DL-based APR
%approaches~\cite{icse20,cure-icse21} have leveraged the context to
%help better fix a bug. They separately consider the surrounding code
%as the context (e.g., lines 2--7, lines 10--15).

\underline{Fifth}, DLFix~\cite{icse20} shows that dedicating a
separate model for context learning can achieve better performance.
DLFix has a two-tier model in which one tree-based LSTM model learns
the context and another one learns the code transformation (from line
8 to line 9). However, it cascades the first LSTM model to the second
one in which the output of the model for contexts is used as a weight
for the one for bug-fixing transformations. This cascading
architecture creates a confounding effect from the inaccuracy of the
learning of the context to the learning of the transformations.

In Section~\ref{sec:overlap}, we will present the study and examples
to illustrate those limitations of the existing DL-based APR approaches.

\subsection{Key Idea}
\label{sec:key-idea}

To address the above issue with the cascading architecture, we design
{\tool}, a solution that treats the learning of contexts and that of
bug-fixing code transformations as a dual-task learning. {\tool}
consists of two models. The first one, the CCL model, is
dedicated for learning code contexts, and the second one, the
CTL model, is for learning bug-fixing code transformations.


%To avoid the confounding effect in a naive solution of detecting buggy
%methods first and then detecting buggy statements in those methods, we
%design an approach that treats detecting dependent CC fixing locations
%as a {\em dual learning} task between them. First, the {\em
%  method-level FL} model (\code{MethFL}) aims to learn the methods
%that need to be modified in the same fix. Second, the {\em
%  statement-level FL} model (\code{StmtFL}) aims to learn the
%co-fixing statements regardless of whether they are in the same or
%different methods.

Intuitively, the two models CCL and CTL are closely dependent on each
other. The learning of the contexts can benefit the learning of
bug-fixing transformations and vice versa. We refer to this relation
as {\em duality}, which can provide some useful constraints for
{\tool} to learn to fix context-dependent bugs. We conjecture that the
join training of the two models can improve the performance of both
models, if we can achieve the shared representations. For example, in
Figure~\ref{fig:motiv}, if the context is observed as containing
\code{getDataset} at line 7, \code{getIndexOf} at line 6, and
\code{return result} at line 10, the likelihood of the fixing change
at line 8 becoming \code{(dataset == null)} is more than that of
\code{(dataset != 0)}. The rationale is that only if the retrieved
data is empty, the result is returned. On the other hand, if the
bug-fixing transformation is observed as \code{(data != null)}
becoming \code{(data == null)}, it is likely to have an assignment
statement to the variable \code{dataset} preceding that checking.
Therefore, in {\tool}, we joinly train CTL for context learning and
CCL for transformation learning with soft-sharing of parameters to
exploit their relation.

Specifically, we use a model called {\em cross-stitch
unit}~\cite{misra2016cross} to connect the CTL and CCL models. The
sharing of representations between them is modeled by the learning a
linear combination of the input features from two models. Cross-stitch
unit helps regularize both CCL and CTL by learning and enforcing
shared representations by combining feature maps. This joint training
enables the dual learning and propagates the impact of context
learning on the transformation learning and vice versa, to improve APR
performance.
