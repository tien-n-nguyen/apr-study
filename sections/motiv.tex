\section{Motivating Example}
\label{motiv:sec}

\subsection{An Example and Observations}

\begin{figure}[t]
	\centering
	\lstset{
		numbers=left,
		numberstyle= \tiny,
		keywordstyle= \color{blue!70},
		commentstyle= \color{red!50!green!50!blue!50},
		frame=shadowbox,
		rulesepcolor= \color{red!20!green!20!blue!20} ,
		xleftmargin=1.5em,xrightmargin=0em, aboveskip=1em,
		framexleftmargin=1.5em,
                numbersep= 5pt,
		language=Java,
    basicstyle=\scriptsize\ttfamily,
    numberstyle=\scriptsize\ttfamily,
    emphstyle=\bfseries,
                moredelim=**[is][\color{red}]{@}{@},
		escapeinside= {(*@}{@*)}
	}
	\begin{lstlisting}[]
public LegendItemCollection getLegendItems() {
  LegendItemCollection result = new LegendItemCollection();
  if (this.plot == null) {
    return result;
  }
  int index = this.plot.getIndexOf(this);
  CategoryDataset dataset = this.plot.getDataset(index);
  (*@{\color{red}{- if (dataset != null) {}@*)
  (*@{\color{cyan}{+ if (dataset == null) {}@*)
      return result;
  int seriesCount = dataset.getRowCount();
  // update result ...
  return result;
}
	\end{lstlisting}
        \vspace{-9pt}
        \caption{Mutual Impact betw. Context and Change Learning}
        \vspace{-8pt}
        \label{fig:motiv}
\end{figure}

%       if (plot.getRowRenderingOrder().equals(SortOrder.ASCENDING)) {
%            for (int i = 0; i < seriesCount; i++) {
%                if (isSeriesVisibleInLegend(i)) {
%                    LegendItem item = getLegendItem(index, i);
%                    if (item != null) {
%                        result.add(item);
%                    }
%                }
%            }
%        }
%        else {
%            for (int i = seriesCount - 1; i >= 0; i--) {
%                if (isSeriesVisibleInLegend(i)) {
%                    LegendItem item = getLegendItem(index, i);
%                    if (item != null) {
%                        result.add(item);
%                    }
%                }
%            }
%        }

%Let us start with a real-world example to motivate our approach.
Fig.~\ref{fig:motiv} shows a real bug from the project \code{Chart}
in the Defects4J dataset. The bug occurred at line 8 in which the
condition for stopping the updating process on the \code{result}
variable is incorrect (\code{if (dataset != null)}). The result is
returned only when the dataset (line 7) is empty. Thus, it was fixed
into \code{if (dataset == null)}.

\noindent {\bf Observation 1 [Fixing Change Depends on Context]}.~As
seen, the bug-fixing change from line 8 to line 9 (\code{if (dataset
  != null)} $\rightarrow$ \code{if (dataset == null)}) depends on the
code context of the method \code{getLegendItems}. On line 7, the
dataset is retrieved via \code{getDataset}. According to the logic of
the program, \code{result} is returned when \code{dataset} is
\code{null}.  Thus, the incorrect checking was fixed into line 9. That
is, that fix \code{if (dataset == null)} (rather than \code{if
  (dataset == 0)}) makes sense in the context of this method.

%consisting of the preceding code (\code{getDataset},
%\code{getIndexOf}, \code{LegendItemCollection}, etc.), and the
%succeeding code (\code{dataset.getRowCount}, \code{return result},
%etc.).

\vspace{2pt}
\noindent {\bf Observation 2 [Learning Key Contextual Features Depends
    on Fixing Change]}. Let us consider the entire method as a
context. Because the change is (\code{if (dataset} \code{!=}
\code{null)} $\rightarrow$ \code{if (dataset} \code{==} \code{null)}),
the key contextual features are likely the statements at lines 6--7
with \code{getIndexOf} and \code{get\-Dataset}, rather than the other
statements, e.g., at lines 2--5.

%\code{this.plot == null} (line 3) or \code{return result;} (line 4).

Despite successes, the state-of-the-art, DL-based models~are
limited in integrating context learning and change learning.

\underline{First}, for the DL-based approaches that learn the fixes
from prior {\em similar bug fixes or
  patterns}~\cite{gupta2017deepfix,white2019sorting,white2016deep},
there might not be any fix similar to Fig.~\ref{fig:motiv}. They focus
on similar fixes with little or no consideration on whether a fix
appears in certain~context.

\underline{Second}, some other DL-based APR approaches focus {\em only
  on learning the changes} to fix an AST subtree or a
statement~\cite{chakrabortycodit,see2017get} without considering the
context. For this example, without examining the context,
%e.g., the preceding code \code{getDataset} or the succeeding code
%\code{getRowCount} or \code{return result},
such a model will make the same change regardless of contexts.

%not likely learn to change line 8 into line 9.

%hata2018learning,tufano2019learning,tufano2018empirical

\underline{Third}, for the machine translation and transformer-based
APR
models~\cite{hata2018learning,tufano2019learning,tufano2018empirical},
the entire method in Fig.~\ref{fig:motiv} is used as the input. {\em
  Without distinguishing the boundary of the context and the fixing
  changes}, such a model faces the noise.
%, i.e., the code irrelevant to the actual fix at lines 8--9.
For example, the code at lines 2--5 on the legends is not crucial for
the fix regarding the dataset at line 9. Thus, such a model could
identify the incorrect location to fix.

\underline{Fourth}, some other DL-based approaches have separate
representations for
contexts~\cite{chen2018sequencer,cure-icse21,lutellier2020coconut}.
SequenceR~\cite{chen2018sequencer},
CoCoNuT~\cite{lutellier2020coconut}, and CURE~\cite{cure-icse21}
extract features in the surrounding context (the method)
%(e.g., lines 2--7, lines 10--15)
to be fed into a DL model.
%to learn to fix.

%These approaches utilize only one DL model for learning the fixes
%using the features extracted from the contexts.

%\underline{Finally}, recent DL-based APR
%approaches~\cite{icse20,cure-icse21} have leveraged the context to
%help better fix a bug. They separately consider the surrounding code
%as the context (e.g., lines 2--7, lines 10--15).

\underline{Fifth}, a recent trend shows that dedicating a separate
model for context learning can perform better than using a single
model~\cite{icse20}. DLFix~\cite{icse20} has two models: one for
context learning and another for transformation learning.
%in which one tree-based LSTM model learns the context and another one
%learns the code transformation (e.g., from line 8 to line 9).
It cascades the first model to the second one in which the output
of the model for contexts is used as a weight for the transformation
learning one. Thus, DLFix~\cite{icse20} suffers two limitations: 1)
it does not capture well both directions of the mutual impact between
two types of learning to help each other,
%(esp. from code-change learning to context learning),
2) it creates confounding inaccuracies as explained.
%
%This cascading architecture creates a confounding effect from the
%inaccuracy of the learning of the context to the learning of the
%transformations.
In Section~\ref{sec:overlap}, we will present our study and examples
to illustrate this.

%those limitations of the existing DL-based APR approaches.

\subsection{Key Ideas}
\label{sec:key-idea}

%To address the above issue with the cascading architecture,

From the observations, our idea is that to improve APR for {\bf
  context-dependent bugs}, we need {\em both better context learning}
(learning the correct contextual features for a bug fix) and {\em
  better code-transformation learning} (learning correct code
changes). {\tool} treats this problem as a dual-task learning between
CCL and CTL. The impact from both directions (explicitly modeled in
{\tool}) helps both models learning better in its own task, leading to
better APR via CTL.

%Tien
%To advance DL-based APR, we {\bf {\em explicitly model both directions
%    of the mutual impact between context learning and transformation
%    learning}}. We design {\tool} that treats context learning and
%transformation learning as a dual task between CCL and CTL.


%with code context learning model (CCL) and code transformation
%learning (CTL).

%{\tool} consists of two models. The first model, CCL, is dedicated to
%learn \underline{c}ode \underline{c}ontexts, and the second model,
%CTL, to learn bug-fixing \underline{c}ode \underline{t}ransformations.


%To avoid the confounding effect in a naive solution of detecting buggy
%methods first and then detecting buggy statements in those methods, we
%design an approach that treats detecting dependent CC fixing locations
%as a {\em dual learning} task between them. First, the {\em
%  method-level FL} model (\code{MethFL}) aims to learn the methods
%that need to be modified in the same fix. Second, the {\em
%  statement-level FL} model (\code{StmtFL}) aims to learn the
%co-fixing statements regardless of whether they are in the same or
%different methods.

%Tien
%Intuitively, the two models CCL and CTL are dependent on each
%other. The learning of the contexts can benefit the learning of
%bug-fixing code transformations and vice versa.
We refer to this relation as {\em duality}, which can provide useful
constraints for {\tool} to learn to fix {\em context-dependent
  bugs}.
%Tien
%We conjecture that the join training of the two models can
%improve the performance of both, if we can achieve the shared
%representations.
%Tien
%For example, in Figure~\ref{fig:motiv}, if the context is observed as
%containing \code{getDataset} at line 7, \code{getIndexOf} at line 6,
%and \code{return result} at line 10, the likelihood of the fixing
%change at line 8 becoming \code{(dataset == null)} is more than that
%of \code{(dataset != 0)}. The rationale is that only if the retrieved
%data is empty, the result is returned. On the other hand, if the
%bug-fixing transformation is observed as \code{(dataset != null)}
%becoming \code{(dataset == null)}, it is likely to have an assignment
%\code{dataset = ...;} in the context preceding \code{(dataset !=
%  null)}.
The join-training in the dual-task learning makes both models learn
the impact/connections between the correct features in the context
(e.g., the lines 6--7 with \code{getIndexOf} and \code{getDataset})
and the correct code changes (line 8 to line 9). Thus, we
joinly train CTL for context learning and CCL for transformation
learning to help both models make those connections, leading to better
APR for context-dependent~bugs.

%with soft-sharing of parameters to exploit their relation.

{\bf {\em We have also adapted/modified the cross-stitch
    unit \cite{misra2016cross} to work with AST representations}} to
connect CTL and CCL. The sharing of representations between them is
modeled by the learning a linear combination of the input features
from two models. Cross-stitch unit helps regularize both CCL and CTL
by learning and enforcing shared representations by combining feature
maps. This joint training {\em propagates the mutual impact} of
context learning and transformation learning. {\em The use of
  cross-stitch unit also helps avoid confounding inaccuracies} in the
cascading architecture.

%and vice versa, to improve APR performance.
